Verifying Docker images...
âœ… Found prebuilt image: ghcr.io/ggml-org/llama.cpp:full
âœ… Found prebuilt image: ghcr.io/ggml-org/llama.cpp:full-cuda
âœ… All required Docker images are available

ğŸ“Š Starting benchmark run: 20250725_152217

ğŸ“Š Benchmarking model: DeepSeek-R1-Distill-Qwen-1.5B-BF16.gguf
  ğŸ” Running cpu variant...
Running benchmark: DeepSeek-R1-Distill-Qwen-1.5B-BF16.gguf - cpu
ğŸ³ Using prebuilt image: ghcr.io/ggml-org/llama.cpp:full
ğŸ“‚ Models directory (absolute): /home/andrepascoa/projects/llmtests/benchmarks/models
ğŸ³ Starting container with command: --bench -m /models/DeepSeek-R1-Distill-Qwen-1.5B-BF16.gguf -o jsonl -fa 1 -t 16 -b 1 -n 0 -p 0 -pg 128,128 -pg 128,512 -pg 512,128 -pg 512,512 -ngl 0 -nopo 1
ğŸ“Š Container output (streaming to file):
==================================================
load_backend: loaded CPU backend from /app/libggml-cpu-haswell.so
âœ… Benchmark completed: DeepSeek-R1-Distill-Qwen-1.5B-BF16.gguf - cpu
  âœ… Completed: DeepSeek-R1-Distill-Qwen-1.5B-BF16.gguf - cpu

ğŸ“Š Benchmarking model: DeepSeek-R1-Distill-Qwen-1.5B-Q4_K_M.gguf
  ğŸ” Running cpu variant...
Running benchmark: DeepSeek-R1-Distill-Qwen-1.5B-Q4_K_M.gguf - cpu
ğŸ³ Using prebuilt image: ghcr.io/ggml-org/llama.cpp:full
ğŸ“‚ Models directory (absolute): /home/andrepascoa/projects/llmtests/benchmarks/models
ğŸ³ Starting container with command: --bench -m /models/DeepSeek-R1-Distill-Qwen-1.5B-Q4_K_M.gguf -o jsonl -fa 1 -t 16 -b 1 -n 0 -p 0 -pg 128,128 -pg 128,512 -pg 512,128 -pg 512,512 -ngl 0 -nopo 1
ğŸ“Š Container output (streaming to file):
==================================================
load_backend: loaded CPU backend from /app/libggml-cpu-haswell.so
âœ… Benchmark completed: DeepSeek-R1-Distill-Qwen-1.5B-Q4_K_M.gguf - cpu
  âœ… Completed: DeepSeek-R1-Distill-Qwen-1.5B-Q4_K_M.gguf - cpu

ğŸ“Š Benchmarking model: DeepSeek-R1-Distill-Qwen-1.5B-Q8_0.gguf
  ğŸ” Running cpu variant...
Running benchmark: DeepSeek-R1-Distill-Qwen-1.5B-Q8_0.gguf - cpu
ğŸ³ Using prebuilt image: ghcr.io/ggml-org/llama.cpp:full
ğŸ“‚ Models directory (absolute): /home/andrepascoa/projects/llmtests/benchmarks/models
ğŸ³ Starting container with command: --bench -m /models/DeepSeek-R1-Distill-Qwen-1.5B-Q8_0.gguf -o jsonl -fa 1 -t 16 -b 1 -n 0 -p 0 -pg 128,128 -pg 128,512 -pg 512,128 -pg 512,512 -ngl 0 -nopo 1
ğŸ“Š Container output (streaming to file):
==================================================
load_backend: loaded CPU backend from /app/libggml-cpu-haswell.so
âœ… Benchmark completed: DeepSeek-R1-Distill-Qwen-1.5B-Q8_0.gguf - cpu
  âœ… Completed: DeepSeek-R1-Distill-Qwen-1.5B-Q8_0.gguf - cpu

ğŸ‰ Benchmark run completed!
ğŸ“Š Total results: 3

[project]
name = "proxy"
version = "0.1.0"
description = "OpenAI-compatible proxy for llama.cpp Docker containers"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "fastapi[standard]>=0.116.1",
    "pytest>=8.4.1",
    "requests>=2.32.4",
    "tqdm>=4.66.0",
    "huggingface_hub>=0.20.0",
    "aiohttp>=3.12.14",
    "pandas>=2.3.1",
    "plotly>=6.2.0",
    "polars>=1.31.0",
    "pyarrow>=21.0.0",
    "tqdm>=4.67.1",
    "tiktoken>=0.5.0",
]

[project.optional-dependencies]
dev = [
]

[project.scripts]
proxy = "main:main"


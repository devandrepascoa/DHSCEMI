[project]
name = "proxy"
version = "0.1.0"
description = "OpenAI-compatible proxy for llama.cpp Docker containers"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "fastapi[standard]>=0.116.1",
    "pytest>=8.4.1",
    "requests>=2.32.4",
    "aiohttp>=3.8.0",
]

[project.optional-dependencies]
dev = [
]

[project.scripts]
proxy = "main:main"

[tool.uv.workspace]
members = [
    "benchmarks",
]
